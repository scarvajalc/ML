{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2 - Exercise 6.\n",
    "#### Modified by: Santiago Carvajal CastaÃ±eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biggie data\n",
      "                                               lyrics\n",
      "0   fuck all you hoes\\nget a grip motherfucker\\nye...\n",
      "1   as i grab the glock put it to your headpiece\\n...\n",
      "2   i dont wanna live no mo\\nsometimes i hear deat...\n",
      "3   to all the ladies in the place with style and ...\n",
      "4   nineteenseventy somethin nigga i dont sweat th...\n",
      "5   another day in the ghetto \\none look outside i...\n",
      "6   live from bedfordstuyverson the livest one\\nre...\n",
      "7   uh uh uh cmon\\nhah sicker than your average\\np...\n",
      "8   uhh uhhh\\nbig po ppa\\nno info for the dea\\nfed...\n",
      "9   uhh its the ten crack commandments\\nwhat uhh u...\n",
      "10  the commission\\nuncle paulie big ditti\\ncaesar...\n",
      "11  relax and take notes while i take tokes of the...\n",
      "12  good evenin ladies and gentlemen\\nhows everybo...\n",
      "13  who shot ya\\nseperate the weak from the obsole...\n",
      "14  when i die fuck it i wanna go to hell\\ncause i...\n",
      "15  when the lala hits ya lyrics just splits ya\\nh...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Dataset from biggie\n",
    "biggie_df = pd.read_csv('biggie_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "biggie_df.columns = ['lyrics']\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "biggie_df['lyrics'] = biggie_df['lyrics'].str.lower()\n",
    "print(\"Biggie data\")\n",
    "print(biggie_df)\n",
    "\n",
    "#Dataset from 2biggie\n",
    "pac_df = pd.read_csv('2pac_lyrics.csv',usecols=[1],encoding='latin-1',header=None)\n",
    "pac_df.columns = ['lyrics']\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.replace('[^\\w\\s]','')\n",
    "pac_df['lyrics'] = pac_df['lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                               line\n",
      "0         0                                  fuck all you hoes\n",
      "1         0                            get a grip motherfucker\n",
      "2         0  yeah this album is dedicated to all the teache...\n",
      "3         0  id never amount to nothin to all the people th...\n",
      "4         0  buildings that i was hustlin in front of that ...\n",
      "5         0  me when i was just tryin to make some money to...\n",
      "6         0  and all the niggas in the struggle you know wh...\n",
      "7         0                   uhha its all good baby baybee uh\n",
      "8         0                                 it was all a dream\n",
      "9         0                    i used to read word up magazine\n",
      "10        0          saltnpepa and heavy d up in the limousine\n",
      "11        0                         hangin pictures on my wall\n",
      "12        0     every saturday rap attack mr magic marley marl\n",
      "13        0                 i let my tape rock til my tape pop\n",
      "14        0     smokin weed and bamboo sippin on private stock\n",
      "15        0   way back when i had the red and black lumberjack\n",
      "16        0                              with the hat to match\n",
      "17        0                   remember rappin duke duhha duhha\n",
      "18        0  you never thought that hip hop would take it t...\n",
      "19        0        now im in the limelight cause i rhyme tight\n",
      "20        0      time to get paid blow up like the world trade\n",
      "21        0               born sinner the opposite of a winner\n",
      "22        0    remember when i used to eat sardines for dinner\n",
      "23        0                  peace to ron g brucey b kid capri\n",
      "24        0                    funkmaster flex lovebug starsky\n",
      "25        0              im blowin up like you thought i would\n",
      "26        0                call the crib same number same hood\n",
      "27        0      uh and if you dont know now you know nigga uh\n",
      "28        0                     you know very well who you are\n",
      "29        0      dont let em hold you down reach for the stars\n",
      "...     ...                                                ...\n",
      "1940      1                dont let em jack you up back you up\n",
      "1941      1                  crack you up and pimpsmack you up\n",
      "1942      1                   you gotta learn to hold your own\n",
      "1943      1  they get jealous when they see you with your m...\n",
      "1944      1             but tell the cops they cant touch this\n",
      "1945      1  i dont trust this when they try to rush i bust...\n",
      "1946      1                         thats the sound of my tool\n",
      "1947      1   you say it aint cool my mama didnt raise no fool\n",
      "1948      1  and as long as i stay black i gotta stay strapped\n",
      "1949      1                        and i never get to lay back\n",
      "1950      1       cause i always got to worry bout the payback\n",
      "1951      1               some buck that i roughed up way back\n",
      "1952      1                  coming back after all these years\n",
      "1953      1               ratatattattattat thats the way it is\n",
      "1954      1  out on bail fresh out of jail california dreaming\n",
      "1955      1  soon as i step on the scene im hearing hoochie...\n",
      "1956      1                     fiending for money and alcohol\n",
      "1957      1  the life of a westside player where cowards di...\n",
      "1958      1  only in cali where we riot not rally to live a...\n",
      "1959      1  in la we wearing chucks not ballys yeah thats ...\n",
      "1960      1  dressed in locs and khaki suits and ride is wh...\n",
      "1961      1  flossing but have caution we collide with othe...\n",
      "1962      1                          famous because we program\n",
      "1963      1  worldwide let them recognize from long beach t...\n",
      "1964      1  bumping and grinding like a slow jam its westside\n",
      "1965      1        so you know the row wont bow down to no man\n",
      "1966      1  say what you say but give me that bomb beat fr...\n",
      "1967      1                  let me serenade the streets of la\n",
      "1968      1  from oakland to sactown the bay area and back ...\n",
      "1969      1             cali is where they put their mack down\n",
      "\n",
      "[1970 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "biggie_lyrics = biggie_df['lyrics'].values\n",
    "biggie_lyrics = [song.split('\\n') for song in biggie_lyrics]\n",
    "biggie_lyrics = [line for song in biggie_lyrics for line in song]\n",
    "pac_lyrics = pac_df['lyrics'].values\n",
    "pac_lyrics = [song.split('\\n') for song in pac_lyrics]\n",
    "pac_lyrics = [line for song in pac_lyrics for line in song]\n",
    "\n",
    "rap_lines = []\n",
    "\n",
    "for line in biggie_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([0,str(line)]))\n",
    "\n",
    "for line in pac_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([1,str(line)]))\n",
    "\n",
    "rap_lines = np.array(rap_lines)\n",
    "\n",
    "\n",
    "rap_lines = pd.DataFrame(rap_lines)\n",
    "rap_lines.columns = ['label','line']\n",
    "rap_lines.head()\n",
    "rap_lines['label'] = rap_lines['label'].replace(['0','1'],[0,1])\n",
    "\n",
    "print(rap_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Santiago\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "   label                                               line\n",
      "0      0                             [fuck, all, you, hoes]\n",
      "1      0                       [get, a, grip, motherfucker]\n",
      "2      0  [yeah, this, album, is, dedicated, to, all, th...\n",
      "3      0  [id, never, amount, to, nothin, to, all, the, ...\n",
      "4      0  [buildings, that, i, was, hustlin, in, front, ...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "rap_lines['line'] = rap_lines['line'].apply(nltk.word_tokenize)\n",
    "print(rap_lines.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[fuck, all, you, hoe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[get, a, grip, motherfuck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[yeah, thi, album, is, dedic, to, all, the, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[id, never, amount, to, nothin, to, all, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[build, that, i, wa, hustlin, in, front, of, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               line\n",
       "0      0                              [fuck, all, you, hoe]\n",
       "1      0                         [get, a, grip, motherfuck]\n",
       "2      0  [yeah, thi, album, is, dedic, to, all, the, te...\n",
       "3      0  [id, never, amount, to, nothin, to, all, the, ...\n",
       "4      0  [build, that, i, wa, hustlin, in, front, of, t..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "rap_lines['line'] = rap_lines['line'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "rap_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the list of words into space-separated strings\n",
    "rap_lines['line'] = rap_lines['line'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1038)\t1\n",
      "  (0, 2519)\t1\n",
      "  (0, 63)\t1\n",
      "  (0, 859)\t1\n",
      "  (1, 1443)\t1\n",
      "  (1, 943)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 888)\t1\n",
      "  (2, 1371)\t1\n",
      "  (2, 2278)\t1\n",
      "  (2, 2217)\t1\n",
      "  (2, 2192)\t1\n",
      "  (2, 2220)\t1\n",
      "  (2, 2272)\t1\n",
      "  (2, 569)\t1\n",
      "  (2, 1143)\t1\n",
      "  (2, 58)\t1\n",
      "  (2, 2232)\t1\n",
      "  (2, 2511)\t1\n",
      "  (2, 63)\t1\n",
      "  (3, 24)\t1\n",
      "  (3, 1283)\t1\n",
      "  (3, 1609)\t1\n",
      "  (3, 1515)\t1\n",
      "  (3, 80)\t1\n",
      "  :\t:\n",
      "  (1967, 1909)\t1\n",
      "  (1967, 1213)\t1\n",
      "  (1967, 2118)\t1\n",
      "  (1967, 1253)\t1\n",
      "  (1967, 1531)\t1\n",
      "  (1967, 1371)\t1\n",
      "  (1967, 2220)\t1\n",
      "  (1968, 97)\t1\n",
      "  (1968, 149)\t1\n",
      "  (1968, 1848)\t1\n",
      "  (1968, 1527)\t1\n",
      "  (1968, 856)\t1\n",
      "  (1968, 642)\t1\n",
      "  (1968, 124)\t1\n",
      "  (1968, 83)\t1\n",
      "  (1968, 2220)\t1\n",
      "  (1968, 2272)\t1\n",
      "  (1969, 328)\t1\n",
      "  (1969, 2222)\t1\n",
      "  (1969, 1327)\t1\n",
      "  (1969, 2446)\t1\n",
      "  (1969, 1718)\t1\n",
      "  (1969, 2228)\t1\n",
      "  (1969, 642)\t1\n",
      "  (1969, 1143)\t1\n"
     ]
    }
   ],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "# to allow one letter words count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")  \n",
    "counts = count_vect.fit_transform(rap_lines['line'])\n",
    "print (counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 2535)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcay: \n",
      "0.766497461928934\n",
      "Confusion matrix: \n",
      "[[63 32]\n",
      " [14 88]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines['label'], test_size=0.1, random_state=69) \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "print(\"Accurcay: \")\n",
    "print(np.mean(predicted == y_test))\n",
    "print(\"Confusion matrix: \")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the results\n",
    "\n",
    "Using Shahrokhian code, we obtained 76.6% Accuracy while in N Lidell , they obtained 75.13% Accuracy.\n",
    "This means that using Shahrokhian code is better. We obtained better results, although, the difference wasn't so big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7309644670050761\n",
      "[[63 39]\n",
      " [14 81]]\n",
      "0.7868020304568528\n",
      "[[58 31]\n",
      " [11 97]]\n",
      "0.7969543147208121\n",
      "[[ 55  24]\n",
      " [ 16 102]]\n",
      "0.7055837563451777\n",
      "[[49 37]\n",
      " [21 90]]\n",
      "0.7360406091370558\n",
      "[[50 38]\n",
      " [14 95]]\n",
      "0.7461928934010152\n",
      "[[ 46  40]\n",
      " [ 10 101]]\n",
      "0.7208121827411168\n",
      "[[56 35]\n",
      " [20 86]]\n",
      "0.7309644670050761\n",
      "[[51 38]\n",
      " [15 93]]\n",
      "0.7461928934010152\n",
      "[[53 32]\n",
      " [18 94]]\n",
      "0.7360406091370558\n",
      "[[59 30]\n",
      " [22 86]]\n",
      "average perfromance\n",
      "0.7436548223350254\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines['label'], test_size=0.1) \n",
    "    model = MultinomialNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print (\"average perfromance\")\n",
    "print (per/10.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
